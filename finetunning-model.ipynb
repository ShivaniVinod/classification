{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14662736,"sourceType":"datasetVersion","datasetId":9367189}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -qU sentence-transformers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-02T11:05:21.540445Z","iopub.execute_input":"2026-02-02T11:05:21.540621Z","iopub.status.idle":"2026-02-02T11:05:26.630243Z","shell.execute_reply.started":"2026-02-02T11:05:21.540602Z","shell.execute_reply":"2026-02-02T11:05:26.629522Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ============================================================\n# V2.1: EMBEDDING-ONLY INTENT MODEL (ANN HARD-NEGATIVE SAFE)\n# ============================================================\n\nfrom __future__ import annotations\n\nimport json\nimport os\nimport random\nimport logging\nimport sys\nimport time\nfrom pathlib import Path\nfrom collections import defaultdict\nfrom typing import Dict, List, Iterable, Tuple\n\nimport torch\nfrom torch.utils.data import DataLoader\n\nfrom sentence_transformers import (\n    SentenceTransformer,\n    InputExample,\n    losses,\n    util\n)\nfrom sentence_transformers.losses import TripletLoss\n\n# ============================================================\n# LOGGING (HARD FLUSH + STEP IDS)\n# ============================================================\n\nlogging.getLogger().handlers.clear()\nlogger = logging.getLogger(\"intent-embedder-v2.1\")\nlogger.setLevel(logging.INFO)\nhandler = logging.StreamHandler(sys.stdout)\nhandler.setFormatter(logging.Formatter(\"%(asctime)s | %(levelname)s | %(message)s\"))\nlogger.addHandler(handler)\nlogger.propagate = False\n\n_STEP = 0\n\ndef log_step(msg: str):\n    global _STEP\n    _STEP += 1\n    logger.info(f\"[STEP {_STEP:02d}] {msg}\")\n    sys.stdout.flush()\n    sys.stderr.flush()\n\ndef log_kv(**kwargs):\n    logger.info(\" | \".join(f\"{k}={v}\" for k, v in kwargs.items()))\n    sys.stdout.flush()\n    sys.stderr.flush()\n\ndef heartbeat(tag: str):\n    logger.info(f\"[HEARTBEAT] {tag} | t={time.time():.2f}\")\n    sys.stdout.flush()\n\n# ============================================================\n# ENV / TORCH HARDENING (NO LOGIC CHANGE)\n# ============================================================\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\nos.environ[\"WANDB_DISABLED\"] = \"true\"\nos.environ[\"WANDB_MODE\"] = \"disabled\"\n\ntorch.set_num_threads(1)\ntorch.set_num_interop_threads(1)\n\n# ============================================================\n# CONFIG\n# ============================================================\n\nBASE_MODEL = \"paraphrase-multilingual-mpnet-base-v2\"\nDATA_JSON_PATH = Path(\"/kaggle/input/training-data-gold-silver-final/training_data_gold_silver_FINAL.json\")\nOUTPUT_DIR = Path(\"/kaggle/working/food_intent_embedder_v2_1\")\nOUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n\nSEED = 42\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nMAX_SEQ_LEN = 128\nBATCH_SIZE = 64\n\nEPOCHS_GOLD = 3\nEPOCHS_SILVER = 1\nEPOCHS_TRIPLET = 1\n\nLR_BASE = 2e-5\nLR_SILVER = 1e-5\nLR_TRIPLET = 1e-5\n\nMAX_GOLD_PAIRS_PER_INTENT = 300\nMAX_GOLD_SILVER_PAIRS_PER_INTENT = 150\nMAX_TRIPLETS_PER_INTENT = 200\nANN_K = 10\n\nrandom.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed_all(SEED)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nlog_step(\"Torch + environment initialized\")\nlog_kv(\n    torch_version=torch.__version__,\n    cuda_available=torch.cuda.is_available(),\n    device=DEVICE,\n)\n\n# ============================================================\n# LOAD DATA\n# ============================================================\n\nlog_step(\"Loading dataset\")\n\nwith open(DATA_JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n    raw_data: Dict[str, Dict[str, List[str]]] = json.load(f)\n\ngold_texts: Dict[str, List[str]] = {}\nsilver_texts: Dict[str, List[str]] = {}\n\nfor intent, tiers in raw_data.items():\n    g = list(set(tiers.get(\"gold\", [])))\n    s = list(set(tiers.get(\"silver\", [])))\n    if g:\n        gold_texts[intent] = g\n    if s:\n        silver_texts[intent] = s\n\nassert set(silver_texts.keys()).issubset(gold_texts.keys())\n\nintents = sorted(gold_texts.keys())\nlog_kv(\n    intents=len(intents),\n    gold_items=sum(len(v) for v in gold_texts.values()),\n    silver_items=sum(len(v) for v in silver_texts.values()),\n)\n\n# ============================================================\n# MODEL INIT\n# ============================================================\n\nlog_step(f\"Initializing model on {DEVICE}\")\nheartbeat(\"before_model_init\")\n\nmodel = SentenceTransformer(BASE_MODEL, device=DEVICE)\nmodel.max_seq_length = MAX_SEQ_LEN\n\nheartbeat(\"after_model_init\")\n\n# ============================================================\n# DATA GENERATORS\n# ============================================================\n\ndef gold_pair_generator() -> Iterable[InputExample]:\n    for intent, texts in gold_texts.items():\n        if len(texts) < 2:\n            continue\n        n = min(len(texts) * 2, MAX_GOLD_PAIRS_PER_INTENT)\n        for _ in range(n):\n            a, b = random.sample(texts, 2)\n            yield InputExample(texts=[a, b])\n\ndef gold_silver_pair_generator() -> Iterable[InputExample]:\n    for intent, g_texts in gold_texts.items():\n        s_texts = silver_texts.get(intent)\n        if not s_texts:\n            continue\n        n = min(len(g_texts), len(s_texts), MAX_GOLD_SILVER_PAIRS_PER_INTENT)\n        for _ in range(n):\n            yield InputExample(\n                texts=[random.choice(g_texts), random.choice(s_texts)]\n            )\n\n# ============================================================\n# STAGE 1: GOLD METRIC LEARNING\n# ============================================================\n\nlog_step(\"Stage 1: Gold metric learning\")\n\ngold_pairs = list(gold_pair_generator())\nlog_kv(gold_pairs=len(gold_pairs))\n\ngold_loader = DataLoader(\n    gold_pairs,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    drop_last=True,\n    num_workers=0,\n)\n\nmnrl_loss = losses.MultipleNegativesRankingLoss(model)\n\nheartbeat(\"before_stage1_fit\")\n\nmodel.fit(\n    train_objectives=[(gold_loader, mnrl_loss)],\n    epochs=EPOCHS_GOLD,\n    optimizer_params={\"lr\": LR_BASE},\n    show_progress_bar=True,\n)\n\nheartbeat(\"after_stage1_fit\")\n\n# ============================================================\n# STAGE 2: GOLD–SILVER SMOOTHING\n# ============================================================\n\nif silver_texts:\n    log_step(\"Stage 2: Gold–Silver smoothing\")\n\n    gs_pairs = list(gold_silver_pair_generator())\n    log_kv(gs_pairs=len(gs_pairs))\n\n    if gs_pairs:\n        gs_loader = DataLoader(\n            gs_pairs,\n            batch_size=BATCH_SIZE,\n            shuffle=True,\n            drop_last=True,\n            num_workers=0,\n        )\n\n        heartbeat(\"before_stage2_fit\")\n\n        model.fit(\n            train_objectives=[(gs_loader, mnrl_loss)],\n            epochs=EPOCHS_SILVER,\n            optimizer_params={\"lr\": LR_SILVER},\n            show_progress_bar=True,\n        )\n\n        heartbeat(\"after_stage2_fit\")\n\n# ============================================================\n# STAGE 3: ANN HARD-NEGATIVE MINING\n# ============================================================\n\nlog_step(\"Stage 3: ANN hard-negative mining\")\n\nall_texts: List[str] = []\nall_labels: List[str] = []\n\nfor intent, samples in gold_texts.items():\n    for s in samples:\n        all_texts.append(s)\n        all_labels.append(intent)\n\nlog_kv(total_texts=len(all_texts))\n\nheartbeat(\"before_encode_all\")\n\nwith torch.no_grad():\n    embeddings = model.encode(\n        all_texts,\n        convert_to_tensor=True,\n        normalize_embeddings=True,\n        batch_size=128,\n    )\n\nheartbeat(\"after_encode_all\")\nlog_kv(embedding_shape=tuple(embeddings.shape))\n\nheartbeat(\"before_ann_search\")\n\nsearch_results = util.semantic_search(\n    embeddings,\n    embeddings,\n    top_k=min(len(all_texts), ANN_K + 1),\n    score_function=util.dot_score,\n)\n\nheartbeat(\"after_ann_search\")\nlog_kv(ann_rows=len(search_results))\n\ntriplets: List[InputExample] = []\nper_intent_count = defaultdict(int)\n\nfor i, neighbors in enumerate(search_results):\n    anchor_text = all_texts[i]\n    anchor_intent = all_labels[i]\n\n    positive = None\n    negative = None\n\n    for hit in neighbors[1:]:\n        j = hit[\"corpus_id\"]\n        if all_labels[j] == anchor_intent and positive is None:\n            positive = all_texts[j]\n        elif all_labels[j] != anchor_intent and negative is None:\n            negative = all_texts[j]\n        if positive and negative:\n            break\n\n    if positive and negative and per_intent_count[anchor_intent] < MAX_TRIPLETS_PER_INTENT:\n        triplets.append(InputExample(texts=[anchor_text, positive, negative]))\n        per_intent_count[anchor_intent] += 1\n\nlog_kv(triplets=len(triplets))\n\nif triplets:\n    batch_size = min(32, len(triplets))\n    triplet_loader = DataLoader(\n        triplets,\n        batch_size=batch_size,\n        shuffle=True,\n        drop_last=(len(triplets) >= batch_size),\n        num_workers=0,\n    )\n\n    try:\n        triplet_loss = TripletLoss(\n            model=model,\n            distance_metric=\"cosine\",\n            margin=0.2,\n        )\n        log_step(\"TripletLoss: cosine + margin\")\n    except Exception as e:\n        log_kv(triplet_loss_fallback=str(e))\n        cosine_dist = lambda x, y: 1 - torch.nn.functional.cosine_similarity(x, y)\n        triplet_loss = TripletLoss(\n            model=model,\n            distance_metric=cosine_dist,\n        )\n\n    heartbeat(\"before_stage3_fit\")\n\n    model.fit(\n        train_objectives=[(triplet_loader, triplet_loss)],\n        epochs=EPOCHS_TRIPLET,\n        optimizer_params={\"lr\": LR_TRIPLET},\n        show_progress_bar=True,\n    )\n\n    heartbeat(\"after_stage3_fit\")\n\n# ============================================================\n# CENTROID BUILD\n# ============================================================\n\nlog_step(\"Building final gold centroids\")\n\ncentroid_texts = []\ncentroid_labels = []\n\nfor intent, texts in gold_texts.items():\n    centroid_texts.extend(texts)\n    centroid_labels.extend([intent] * len(texts))\n\nheartbeat(\"before_centroid_encode\")\n\nwith torch.no_grad():\n    emb = model.encode(\n        centroid_texts,\n        convert_to_tensor=True,\n        normalize_embeddings=True,\n        batch_size=128,\n    )\n\nheartbeat(\"after_centroid_encode\")\n\ncentroids: Dict[str, torch.Tensor] = {}\noffset = 0\nfor intent, texts in gold_texts.items():\n    n = len(texts)\n    c = emb[offset:offset + n].mean(dim=0)\n    centroids[intent] = util.normalize_embeddings(c.unsqueeze(0))[0]\n    offset += n\n\nintent_list = sorted(centroids.keys())\ncentroid_matrix = torch.stack([centroids[i] for i in intent_list])\n\n# ============================================================\n# SAVE ARTIFACTS\n# ============================================================\n\nlog_step(\"Saving artifacts\")\n\nmodel.save(str(OUTPUT_DIR / \"encoder\"))\n\ntorch.save(\n    {\n        \"intent_list\": intent_list,\n        \"centroids\": centroid_matrix.cpu(),\n    },\n    OUTPUT_DIR / \"centroids.pt\",\n)\n\nwith open(OUTPUT_DIR / \"meta.json\", \"w\") as f:\n    json.dump(\n        {\n            \"base_model\": BASE_MODEL,\n            \"intents\": intent_list,\n            \"training\": {\n                \"gold_epochs\": EPOCHS_GOLD,\n                \"silver_epochs\": EPOCHS_SILVER,\n                \"triplet_epochs\": EPOCHS_TRIPLET,\n                \"losses\": [\n                    \"MultipleNegativesRankingLoss\",\n                    \"TripletLoss (ANN hard negatives)\",\n                ],\n            },\n        },\n        f,\n        indent=2,\n    )\n\nlog_step(\"Training complete\")\n\n# ============================================================\n# INFERENCE (OPEN WORLD)\n# ============================================================\n\n@torch.no_grad()\ndef predict(\n    text: str,\n    min_similarity: float = 0.45,\n    min_margin: float = 0.05,\n) -> Tuple[str, float, float]:\n\n    emb = model.encode(\n        [text],\n        convert_to_tensor=True,\n        normalize_embeddings=True,\n    )\n\n    sims = util.dot_score(emb, centroid_matrix)[0]\n    top2 = torch.topk(sims, k=2)\n\n    best_id = top2.indices[0].item()\n    best_sim = top2.values[0].item()\n    margin = (top2.values[0] - top2.values[1]).item()\n\n    if best_sim < min_similarity or margin < min_margin:\n        return \"UNKNOWN\", best_sim, margin\n\n    return intent_list[best_id], best_sim, margin\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-02T11:05:26.632334Z","iopub.execute_input":"2026-02-02T11:05:26.632563Z","iopub.status.idle":"2026-02-02T11:13:58.525923Z","shell.execute_reply.started":"2026-02-02T11:05:26.632538Z","shell.execute_reply":"2026-02-02T11:13:58.525384Z"}},"outputs":[{"name":"stderr","text":"2026-02-02 11:05:44.195141: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1770030344.395753      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1770030344.451642      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1770030344.941018      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770030344.941057      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770030344.941060      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770030344.941063      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"2026-02-02 11:06:00,694 | INFO | [STEP 01] Torch + environment initialized\n2026-02-02 11:06:00,695 | INFO | torch_version=2.8.0+cu126 | cuda_available=True | device=cuda\n2026-02-02 11:06:00,697 | INFO | [STEP 02] Loading dataset\n2026-02-02 11:06:01,005 | INFO | intents=12 | gold_items=50930 | silver_items=33039\n2026-02-02 11:06:01,007 | INFO | [STEP 03] Initializing model on cuda\n2026-02-02 11:06:01,008 | INFO | [HEARTBEAT] before_model_init | t=1770030361.01\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0360525359a84feabd38b7a5253b9ac3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0bee219ded9e4a63b974d0fddac1b36a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1b7409e02854d7db8393cb8d749e0c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c0acd7ea37d43f78a47b6e823c05806"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/723 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1513a0ac4464d098d3e021464880acd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4de6a7abb934fe69f36629c55570e27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/402 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"584b55bf5d1b4cea91975a3e75c1523c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd3320e3edb44570a3ed9425155031ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"106479aa4ffc4c71b53d0b2f48b4a97e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7233d14b4474d398d948fc551dc1aa8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72c5697a86ba43ccbbac9108ca5c609d"}},"metadata":{}},{"name":"stdout","text":"2026-02-02 11:06:08,145 | INFO | [HEARTBEAT] after_model_init | t=1770030368.14\n2026-02-02 11:06:08,146 | INFO | [STEP 04] Stage 1: Gold metric learning\n2026-02-02 11:06:08,156 | INFO | gold_pairs=3512\n2026-02-02 11:06:08,158 | INFO | [HEARTBEAT] before_stage1_fit | t=1770030368.16\n","output_type":"stream"},{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='162' max='162' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [162/162 03:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"2026-02-02 11:10:06,831 | INFO | [HEARTBEAT] after_stage1_fit | t=1770030606.83\n2026-02-02 11:10:06,833 | INFO | [STEP 05] Stage 2: Gold–Silver smoothing\n2026-02-02 11:10:06,836 | INFO | gs_pairs=1368\n2026-02-02 11:10:06,838 | INFO | [HEARTBEAT] before_stage2_fit | t=1770030606.84\n","output_type":"stream"},{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [21/21 00:25, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"2026-02-02 11:10:34,898 | INFO | [HEARTBEAT] after_stage2_fit | t=1770030634.90\n2026-02-02 11:10:34,899 | INFO | [STEP 06] Stage 3: ANN hard-negative mining\n2026-02-02 11:10:34,910 | INFO | total_texts=50930\n2026-02-02 11:10:34,911 | INFO | [HEARTBEAT] before_encode_all | t=1770030634.91\n2026-02-02 11:11:37,750 | INFO | [HEARTBEAT] after_encode_all | t=1770030697.75\n2026-02-02 11:11:37,752 | INFO | embedding_shape=(50930, 768)\n2026-02-02 11:11:37,753 | INFO | [HEARTBEAT] before_ann_search | t=1770030697.75\n2026-02-02 11:11:39,362 | INFO | [HEARTBEAT] after_ann_search | t=1770030699.36\n2026-02-02 11:11:39,363 | INFO | ann_rows=50930\n2026-02-02 11:11:39,517 | INFO | triplets=2266\n2026-02-02 11:11:39,519 | INFO | triplet_loss_fallback=TripletLoss.__init__() got an unexpected keyword argument 'margin'\n2026-02-02 11:11:39,520 | INFO | [HEARTBEAT] before_stage3_fit | t=1770030699.52\n","output_type":"stream"},{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [70/70 01:11, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"2026-02-02 11:12:53,225 | INFO | [HEARTBEAT] after_stage3_fit | t=1770030773.23\n2026-02-02 11:12:53,227 | INFO | [STEP 07] Building final gold centroids\n2026-02-02 11:12:53,229 | INFO | [HEARTBEAT] before_centroid_encode | t=1770030773.23\n2026-02-02 11:13:56,103 | INFO | [HEARTBEAT] after_centroid_encode | t=1770030836.10\n2026-02-02 11:13:56,107 | INFO | [STEP 08] Saving artifacts\n2026-02-02 11:13:58,522 | INFO | [STEP 09] Training complete\n","output_type":"stream"}],"execution_count":2}]}